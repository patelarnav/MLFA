# -*- coding: utf-8 -*-
"""20AG36020_Assgn-5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m4OrK5tDw-Iu_6CbuQAYQf_kcwZ9Ae3Y
"""

#20AG36020
#Arnav Patel

#Ans for 1st question

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as dsets

torch.manual_seed(0)

# Step 1: Load the MNIST dataset
train_dataset = dsets.MNIST(
    root='./data',
    train=True,
    transform=transforms.ToTensor(),
    download=True
)

test_dataset = dsets.MNIST(
    root='./data',
    train=False,
    transform=transforms.ToTensor()
)

batch_size = 200
n_iters = 6000
num_epochs = n_iters / (len(train_dataset) / batch_size)
num_epochs = int(num_epochs)

# Step 2: Prepare data loaders
train_loader = torch.utils.data.DataLoader(
    dataset=train_dataset,
    batch_size=batch_size,
    shuffle=True
)

test_loader = torch.utils.data.DataLoader(
    dataset=test_dataset,
    batch_size=batch_size,
    shuffle=False
)

class FeedforwardNeuralNetModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
        super(FeedforwardNeuralNetModel, self).__init__()
        layers = []
        layers.append(nn.Flatten())
        for _ in range(num_layers):
            layers.append(nn.Linear(input_dim, hidden_dim))
            layers.append(nn.ReLU())
            input_dim = hidden_dim
        layers.append(nn.Linear(hidden_dim, output_dim))
        self.layers = nn.Sequential(*layers)

    def forward(self, x):
        return self.layers(x)

depths = [2, 4, 8]
accuracies = []
trained_models = []

input_dim = 28 * 28
hidden_dim = 50
output_dim = 10
learning_rate = 0.001

for depth in depths:
    # Step 3: Instantiate model, loss function, and optimizer
    model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, num_layers=depth)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    for epoch in range(num_epochs):
        model.train()
        for i, (images, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            outputs = model(images.view(-1, 28*28))
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Step 4: Testing the model
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images.view(-1, 28*28))
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    accuracies.append(accuracy)
    trained_models.append(model)
    print(f"Network with {depth} hidden layers: Test Accuracy = {accuracy:.2f}%")

#Ans for 2nd question
# Function to perturb the model
def perturb_model(model, layer_idx, perturbation_std):
    perturbed_model = model
    for i, param in enumerate(perturbed_model.parameters()):
        if i == layer_idx:
            param.data += torch.randn(param.size()) * perturbation_std
    return perturbed_model

# Standard deviation for perturbation
perturbation_std = 0.025

# Iterate over trained models and rank layers by performance deviation for each depth
for depth, original_model in zip(depths, trained_models):
    original_accuracy = accuracies[depths.index(depth)]
    print(f"Original Test Accuracy for {depth} hidden layers: {original_accuracy:.2f}%")

    performance_deviation = []

    for layer_idx in range(1, depth):
        # Create a perturbed model for the current layer
        perturbed_model = perturb_model(original_model, layer_idx, perturbation_std)

        # Test the perturbed model on MNIST test data
        perturbed_model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in test_loader:
                outputs = perturbed_model(images.view(-1, 28*28))
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        deviation = original_accuracy - accuracy
        performance_deviation.append((deviation, layer_idx))

    performance_deviation.sort(reverse=True)

    print(f"Ranking of Layers for {depth} hidden layers:")
    for deviation, layer_idx in performance_deviation:
        print(f"Layer {layer_idx}: Deviation = {deviation:.2f}%")
