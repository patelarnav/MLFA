# -*- coding: utf-8 -*-
"""Lab_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l_QZRTaaBtamRrQ5Btxg4WhvnJihzVDh
"""

import numpy as np
import pandas as pd

np.random.seed(0)

data = pd.read_csv('/content/Iris.csv')

data.drop(columns = ['Id'],inplace=True)

map = {'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2}

data['Species'] = data['Species'].apply(lambda x: map[x])

from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score
from collections import Counter

X = data.copy().drop(['Species'],axis=1)
y = data['Species']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

X_train = X_train.values
X_test = X_test.values

y_train = y_train.values
y_test = y_test.values

X_train.shape , X_test.shape
y_train.shape ,  y_test.shape

'''
Implementation of distance weighted K-NN algorithm (KNN_Distance) from scratch
'''

class DistanceWeightedKNN:
    #Intializing k value
    def __init__(self, k):
        self.k = k

    def fit(self, X_train, y_train):
        self.X_train = X_train
        self.y_train = y_train

    def euclidean_distance(self, x1, x2):
        return np.sqrt(np.sum((x1 - x2) ** 2))

    def weighted_distance(self, x1, x2):
        distance = self.euclidean_distance(x1, x2)
        return 1 / (distance ** 2)

    def predict(self, X_test):
        y_pred = []
        for x in X_test:
            # Calculating the distances from the test point to all training points
            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]

            # Getting the indices of the k-nearest neighbors
            k_indices = np.argsort(distances)[:self.k]

            # Calculating weighted distances for the k-nearest neighbors
            weighted_distances = [self.weighted_distance(x, self.X_train[i]) for i in k_indices]

            # Get the corresponding labels of the k-nearest neighbors
            k_nearest_labels = [self.y_train[i] for i in k_indices]

            # Prediction of the class label by weighted majority vote
            weighted_votes = dict()
            for label, weight in zip(k_nearest_labels, weighted_distances):
                if label in weighted_votes:
                    weighted_votes[label] += weight
                else:
                    weighted_votes[label] = weight

            # Selecting the class label with the highest weighted vote
            predicted_label = max(weighted_votes, key=weighted_votes.get)
            y_pred.append(predicted_label)

        return y_pred

    def accuracy(self, y_true, y_pred):
        correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)
        total = len(y_true)
        return correct / total

'''
#####-----------------------------------------EXPERIMENT-01------------------########
'''


k_values = [1, 3, 5, 10, 20]
accuracy_values = []

# Iterating through different K values
for k in k_values:
    # Create and fit the KNN_Distance model with the current K value
    knn = DistanceWeightedKNN(k=k)
    knn.fit(X_train, y_train)

    # Make predictions
    y_pred = knn.predict(X_test)

    # Calculate accuracy and store it
    accuracy = knn.accuracy(y_test, y_pred)
    accuracy_values.append(accuracy)

# Plot Percentage Accuracy vs. K
plt.figure(figsize=(8, 6))
plt.plot(k_values, accuracy_values, marker='o', linestyle='-')
plt.title('Percentage Accuracy vs. K Value')
plt.xlabel('K Value')
plt.ylabel('Percentage Accuracy')
plt.xticks(k_values)
plt.grid(True)

# Find the best K value
best_k = k_values[np.argmax(accuracy_values)]
best_accuracy = max(accuracy_values)
print(f"Best K value: {best_k}")
print(f"Highest Accuracy based on the given data : {best_accuracy * 100:.2f}%")

plt.show()

'''
#####-----------------------------------------EXPERIMENT-02------------------########
'''
# Optimal K value obtained from Experiment 1
optimal_k = 3

# Define a list of noise levels (10%, 20%, ..., 90%)
noise_levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# Initialize lists to store accuracy values for each noise level
accuracy_values_with_noise = []
accuracy_values_without_noise = []

# Iterate through different noise levels
for noise_fraction in noise_levels:
    # Add Gaussian noise to a fraction of the training data
    num_samples_with_noise = int(noise_fraction * len(X_train))
    noise = np.random.normal(0, 2.0, size=(num_samples_with_noise, X_train.shape[1]))
    X_train_with_noise = np.copy(X_train)
    X_train_with_noise[:num_samples_with_noise] += noise

    # Create and fit the KNN_Distance model with the optimal K value
    knn = DistanceWeightedKNN(k=optimal_k)
    knn.fit(X_train_with_noise, y_train)

    # Make predictions with noise
    y_pred_with_noise = knn.predict(X_test)

    # Calculate accuracy with noise
    accuracy_with_noise = knn.accuracy(y_test, y_pred_with_noise)
    accuracy_values_with_noise.append(accuracy_with_noise)

    # Calculate accuracy without noise for comparison
    knn.fit(X_train, y_train)  # Re-fit the model without noise
    y_pred_without_noise = knn.predict(X_test)
    accuracy_without_noise = knn.accuracy(y_test, y_pred_without_noise)
    accuracy_values_without_noise.append(accuracy_without_noise)

# Plot Percentage Accuracy vs. Noise Level
plt.figure(figsize=(8, 6))
plt.plot(noise_levels, accuracy_values_with_noise, marker='o', linestyle='-', label='With Noise')
plt.plot(noise_levels, accuracy_values_without_noise, marker='o', linestyle='-', label='Without Noise')
plt.title('Percentage Accuracy vs. Noise Level')
plt.xlabel('Noise Level (Fraction of Training Data)')
plt.ylabel('Percentage Accuracy')
plt.xticks(noise_levels)
plt.legend()
plt.grid(True)

plt.show()









